{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7d16d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The skip_kernel_extension extension is already loaded. To reload it, use:\n",
      "  %reload_ext skip_kernel_extension\n"
     ]
    }
   ],
   "source": [
    "%load_ext skip_kernel_extension\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# import xgboost\n",
    "import time\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "from Pamona import *\n",
    "from nonlinear_manifold import *\n",
    "from union_com import *\n",
    "import math\n",
    "# from mmd_ma import *\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import *\n",
    "from eval import *\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "import scipy.cluster.hierarchy as sch\n",
    "from sklearn.cluster import AgglomerativeClustering \n",
    "\n",
    "from itertools import cycle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from collections import Counter\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from scipy import stats\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import ot\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from scipy.spatial.distance import cdist\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.metrics import mean_squared_error, explained_variance_score,accuracy_score,balanced_accuracy_score, f1_score\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de11e67",
   "metadata": {},
   "source": [
    "##### Load A549 here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4140fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Cell magic `%%` not found.\n"
     ]
    }
   ],
   "source": [
    "%% skip True\n",
    "# LOAD Data and Labels\n",
    "ge = pd.read_csv(\"./A549/A549_scRNA_1183Genes_2392cells_F100_C50.csv\")\n",
    "ge.index=ge[\"Unnamed: 0\"]\n",
    "ge = ge.drop([\"Unnamed: 0\"], axis=1)\n",
    "ge = ge.T\n",
    "\n",
    "snp = pd.read_csv(\"./A549/A549_scATAC_5154Loci_2392cells_F100_C50.csv\")\n",
    "snp.index=snp[\"Unnamed: 0\"]\n",
    "snp = snp.drop([\"Unnamed: 0\"], axis=1)\n",
    "snp = snp.T\n",
    "\n",
    "pheno = pd.read_csv(\"./Pamona/A549_labels.csv\")\n",
    "cellLabels = pd.read_csv(\"./A549/cellLabels.csv\", header=None)[1:]\n",
    "pheno[\"Labels\"] = cellLabels[1]\n",
    "labels = pheno[pheno[\"Labels\"].isin(ge.index)]\n",
    "\n",
    "ge = ge.reset_index(drop=True)\n",
    "snp = snp.reset_index(drop=True)\n",
    "labels = labels.reset_index(drop=True)\n",
    "\n",
    "# SPLIT Train/Test\n",
    "geXTrain, geXTest, geYTrain, geYTest = train_test_split(ge[ge.columns[:]],labels[\"Time\"],test_size=0.2,random_state=11)\n",
    "snpXTrain = snp[snp.columns[:]].loc[geXTrain.index]\n",
    "snpXTest = snp[snp.columns[:]].loc[geXTest.index]\n",
    "\n",
    "phenoYTrain = labels.iloc[geYTrain.index]\n",
    "phenoYTest = labels.iloc[geYTest.index]\n",
    "\n",
    "# REORDER AND PICK TOP Peaks\n",
    "topSNP = pd.DataFrame(snpXTrain.std().sort_values(ascending=False)).index\n",
    "snpXTrain = snpXTrain[topSNP[:1183]]\n",
    "snpXTest = snpXTest[topSNP[:1183]]\n",
    "\n",
    "topGE = pd.DataFrame(geXTrain.std().sort_values(ascending=False)).index\n",
    "geXTrain = geXTrain[topGE[:]]\n",
    "geXTest = geXTest[topGE[:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb888f5",
   "metadata": {},
   "source": [
    "##### Load Liu Cancer here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1198b94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%skip True  #skips cell\n",
    "ge = pd.read_csv(\"./liu_scrna_preprocessed_with_genes.csv\")\n",
    "\n",
    "snp = pd.read_csv(\"./liu_scatac_preprocessed.csv\")\n",
    "snp.index=snp[\"rownames\"]\n",
    "snp = snp.drop([\"rownames\"], axis=1)\n",
    "snp = snp.T\n",
    "\n",
    "for col in snp.columns:\n",
    "    snp[col] = [1 if i>0 else 0 for i in snp[col].to_list()]\n",
    "    \n",
    "geTemp = pd.read_csv(\"./liu_scrna_preprocessed.csv\")\n",
    "geTemp.index=geTemp[\"rownames\"]\n",
    "geTemp = geTemp.drop([\"rownames\"], axis=1)\n",
    "geTemp = geTemp.T\n",
    "\n",
    "ctnames=[]\n",
    "for ct in geTemp.index:\n",
    "    if \"HCT\" in ct:\n",
    "        ctnames.append(\"HCT116\")\n",
    "    elif \"Hela\" in ct:\n",
    "        ctnames.append(\"Hela\")\n",
    "    elif \"K562\" in ct:\n",
    "        ctnames.append(\"K562\")\n",
    "\n",
    "celltypedf = pd.DataFrame(ctnames,columns=[\"CellType\"])\n",
    "\n",
    "ge = ge.reset_index(drop=True)\n",
    "snp = snp.reset_index(drop=True)\n",
    "\n",
    "transformer = Normalizer().fit(ge)  # fit does nothing.\n",
    "geDF_norm = pd.DataFrame(transformer.transform(ge), index = ge.index, columns=ge.columns)\n",
    "\n",
    "geDF_norm = geDF_norm\n",
    "snpDF_norm = snp\n",
    "\n",
    "topGE = pd.DataFrame(geDF_norm.std().sort_values(ascending=False)).index\n",
    "geDF_norm_FS = geDF_norm[topGE[:10000]]\n",
    "\n",
    "topSNP = pd.DataFrame(snpDF_norm.std().sort_values(ascending=False)).index\n",
    "snpDF_norm_FS = snpDF_norm[topSNP[:10000]]\n",
    "\n",
    "geXTrain, geXTest, geYTrain, geYTest = train_test_split(geDF_norm_FS[geDF_norm_FS.columns[:10000]],celltypedf['CellType'],test_size=0.4,random_state=11)\n",
    "snpXTrain = snpDF_norm_FS[snpDF_norm_FS.columns[:10000]].loc[geXTrain.index]\n",
    "snpXTest = snpDF_norm_FS[snpDF_norm_FS.columns[:10000]].loc[geXTest.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b34ef0",
   "metadata": {},
   "source": [
    "##### Load HCC here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e16f040",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip True  #skips cell\n",
    "ge = pd.read_csv(\"./human_cerebral_cortex/scRNAWithGenesSeurat_afterPreprocessing_09_08.csv\")\n",
    "snp = pd.read_csv(\"./human_cerebral_cortex/scATACWithLociSeurat_afterPreprocessing_09_08.csv\")\n",
    "\n",
    "ge = ge.reset_index(drop=True)\n",
    "snp = snp.reset_index(drop=True)\n",
    "\n",
    "geXTrain, geXTest = train_test_split(ge[ge.columns[:]],test_size=0.2,random_state=11)\n",
    "snpXTrain = snp.loc[geXTrain.index]\n",
    "snpXTest = snp.loc[geXTest.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754e0be5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95e2144",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13c29596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%skip True  #skips cell\n",
    "\n",
    "mod2 = geDF_norm_FS# < input reference modality here - Y (we know Y and Y_hat, for example SNP,RNA)> \n",
    "mod1 = snpDF_norm_FS# < input query modality here - X (we know only X, predict X_hat, for example GE,ELEC) >\n",
    "labels = None# < input known phenotype labels here >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a49726",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7c265d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%skip True  #skips cell\n",
    "\n",
    "hc = AgglomerativeClustering(n_clusters = 4, affinity = 'euclidean', linkage ='ward')\n",
    "hclabels=hc.fit_predict(snpDF_norm_FS.to_numpy())\n",
    "# hclabels = [\",\".join(item) for item in hclabels.astype(str)]\n",
    "labels = pd.DataFrame(hclabels, columns = [\"HC\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84f67008",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Split into Train-Test\n",
    "if labels is not None:\n",
    "    mod2XTrain, mod2XTest, labelYTrain, labelYTest = train_test_split(mod2,labels,test_size=0.2,random_state=11)\n",
    "else:\n",
    "    mod2XTrain, mod2XTest = train_test_split(mod2,test_size=0.2,random_state=11)\n",
    "mod1XTrain = mod1.loc[mod2XTrain.index]\n",
    "mod1XTest = mod1.loc[mod2XTest.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8628fec8",
   "metadata": {},
   "source": [
    "##### Load PBMC here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72e76a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip True\n",
    "mod2XTrain = pd.read_csv(\"./PBMC_Multigrate_Seurat/PBMC_Seurat_RNA_train_filtered.csv\")\n",
    "mod2XTest = pd.read_csv(\"./PBMC_Multigrate_Seurat/PBMC_Seurat_RNA_test_filtered.csv\")\n",
    "\n",
    "mod1XTrain = pd.read_csv(\"./PBMC_Multigrate_Seurat/PBMC_Seurat_ADT_train.csv\")\n",
    "mod1XTest = pd.read_csv(\"./PBMC_Multigrate_Seurat/PBMC_Seurat_ADT_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a800f74",
   "metadata": {},
   "source": [
    "##### Load MOFA+, Seurat predicted correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5618492f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['MOFA+', 'CMOT_Unioncom', 'CMOT_clustering_align_1%',\n",
       "       'CMOT_clustering_align_25%', 'CMOT_clustering_align_50%',\n",
       "       'CMOT_clustering_align_75%', 'CMOT_clustering_align_100%', 'Seurat'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predCorrdf = pd.read_csv(\"predcorrdf_ROSMAP_80_20.csv\")\n",
    "predCorrdf.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1a47b4",
   "metadata": {},
   "source": [
    "##################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447d591e",
   "metadata": {},
   "source": [
    "**Input:** X & Y modalities for training; Y_hat as single modality;\n",
    "\n",
    "**Output:** predict X_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0daa53ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_samples(X,Y,percent_align_n,d=5,mu=0.5, method=\"NMA\"):\n",
    "    random.seed(30)\n",
    "    \n",
    "    if method == \"NMA\":\n",
    "        n = random.sample(range(0, len(X)), int((percent_align_n)*len(X)))\n",
    "        obj = nonlinear_Manifold(X, Y,d,mu,percent_align=n)\n",
    "        X_aligned,Y_aligned = obj.run(as_file=False)\n",
    "    elif method == \"Unioncom\":\n",
    "        d=5\n",
    "        obj = Unioncom(X, Y,d,epoch_pd=700, epoch_DNN=900)\n",
    "        X_aligned,Y_aligned = obj.run(as_file=False)\n",
    "    return X_aligned,Y_aligned\n",
    "\n",
    "def kmeans(X,Y,k=6):\n",
    "    X_Y = pd.concat([X,Y]).to_numpy()\n",
    "\n",
    "    kmeanModel = KMeans(n_clusters=6).fit(X)\n",
    "    kmeanModel.fit(X_Y)\n",
    "    clusterLabels = kmeanModel.labels_  \n",
    "    return clusterLabels\n",
    "\n",
    "def optimal_transport(Xs,Xt,reg_e, reg_cl,ys=None,method=\"lpl1_reg\"):\n",
    "   \n",
    "    if method == \"emd\":\n",
    "        ot_emd = ot.da.EMDTransport()\n",
    "        ot_emd.fit(Xs=Xs, Xt=Xt)\n",
    "        transp_Xs_emd = ot_emd.transform(Xs=Xs)        \n",
    "        return transp_Xs_emd\n",
    "\n",
    "    elif method == \"sinkhorn\":\n",
    "        ot_sinkhorn = ot.da.SinkhornTransport(reg_e=1e-1)\n",
    "        ot_sinkhorn.fit(Xs=Xs, Xt=Xt)\n",
    "        transp_Xs_sinkhorn = ot_sinkhorn.transform(Xs=Xs)\n",
    "        return transp_Xs_sinkhorn\n",
    "\n",
    "    elif method == \"lpl1_reg\":\n",
    "        ot_lpl1 = ot.da.SinkhornLpl1Transport(reg_e=reg_e, reg_cl=reg_cl)\n",
    "        ot_lpl1.fit(Xs=Xs, ys=ys, Xt=Xt)\n",
    "        transp_Xs_lpl1 = ot_lpl1.transform(Xs=Xs)        \n",
    "        return transp_Xs_lpl1\n",
    "       \n",
    "    elif method == \"emd_laplace\":\n",
    "        ot_emd_laplace = ot.da.EMDLaplaceTransport(reg_lap=10, reg_src=10)\n",
    "        ot_emd_laplace.fit(Xs=Xs, Xt=Xt)\n",
    "        transp_Xs_emd_laplace = ot_emd_laplace.transform(Xs=Xs)\n",
    "        return transp_Xs_emd_laplace\n",
    "        \n",
    "    elif method == \"l1l2_reg\":\n",
    "        ot_l1l2 = ot.da.SinkhornL1l2Transport(reg_e=1e-1, reg_cl=2e0, max_iter=20,\n",
    "                                      verbose=True)\n",
    "        ot_l1l2.fit(Xs=Xs, ys=ys, Xt=Xt)\n",
    "        transp_Xs_l1l2 = ot_l1l2.transform(Xs=Xs)\n",
    "        return transp_Xs_l1l2\n",
    "    \n",
    "def get_nn(X,ys,k,components,targetcomponent):\n",
    "    knn = NearestNeighbors(n_neighbors=k)\n",
    "    knn.fit(components)\n",
    "    neighDist, neigh = knn.kneighbors(targetcomponent, return_distance=True)\n",
    "    nn = X.iloc[neigh[0]]\n",
    "    nnL = ys[neigh[0]]\n",
    "    \n",
    "    return nn, nnL, neighDist,neigh\n",
    "\n",
    "def get_corr_with_n(nn,targetGE):\n",
    "    for idx,row in nn.iterrows():\n",
    "        b = np.array(row).reshape(1,-1)\n",
    "        corr = stats.pearsonr(targetGE[0][:150], b[0][:150])\n",
    "        nnCorr.append(corr[0])\n",
    "        \n",
    "    return nnCorr\n",
    "\n",
    "def get_phenotype(X,ys,transp_Xs,targetSNP,k,topFeat,pca=False):\n",
    "    \n",
    "#     targetSNP = Xt[targetIdx][:topFeat].reshape(1,-1)\n",
    "    Xp = transp_Xs[:,:topFeat]\n",
    "\n",
    "    if pca:\n",
    "        pca = PCA(n_components=4)\n",
    "        components = pca.fit_transform(Xp)\n",
    "        targetcomponent = pca.transform(targetSNP)\n",
    "    else:\n",
    "        components = Xp\n",
    "        targetcomponent = targetSNP\n",
    "    \n",
    "    nn,nnL,neighDist,neighIdx = get_nn(X,ys,k,components,targetcomponent)\n",
    "\n",
    "    neighDist = neighDist[0]\n",
    "    for i in range(len(neighDist)):\n",
    "        neighDist[i] = math.exp(-neighDist[i])\n",
    "    \n",
    "    nn = nn.multiply(neighDist, axis=0)\n",
    "    \n",
    "    averageGE = nn.mean()\n",
    "    return averageGE\n",
    "\n",
    "def predict_phenotype(transp_Xs,Y_hat,X,ys,k,topFeat):\n",
    "\n",
    "    predGEdf = pd.DataFrame(columns=X.columns)\n",
    "    for i in range(len(Y_hat)):\n",
    "        Y_hat_i = Y_hat.to_numpy()[i][:topFeat].reshape(1,-1)\n",
    "        predGE = get_phenotype(X,ys,transp_Xs,Y_hat_i,k,topFeat)\n",
    "        predGEdf = pd.concat([predGEdf,pd.DataFrame(predGE).T])\n",
    "    return predGEdf\n",
    "\n",
    "def check_correlation(predicted_p,X_hat):\n",
    "    predCorr = []\n",
    "    for i in range(len(predicted_p)):\n",
    "        a = predicted_p.iloc[i][:]\n",
    "        b = X_hat.iloc[i][:]\n",
    "        corr = stats.pearsonr(a,b)\n",
    "        predCorr.append(corr[0])\n",
    "    return predCorr\n",
    "\n",
    "def get_best_match(geNMA,snpNMA):\n",
    "    best_match =[]\n",
    "    for i in range(len(snpNMA)):\n",
    "        X = geNMA.to_numpy()\n",
    "        y_i = snpNMA.iloc[i].to_numpy().reshape(1,-1)\n",
    "        knn = NearestNeighbors(n_neighbors=1).fit(X)\n",
    "        dist,indices = knn.kneighbors(y_i)\n",
    "        best_match.append(indices[0][0])\n",
    "    return best_match\n",
    "\n",
    "\n",
    "def find_best_match_df(best_match,geNMA, geXTrain):\n",
    "    geNMABestMatch = geNMA.copy()\n",
    "    geNMABestMatch = geNMABestMatch.reset_index()\n",
    "    geNMABestMatch = geNMABestMatch.reindex(best_match)\n",
    "    geNMABestMatch = geNMABestMatch.drop([\"index\"], axis=1)\n",
    "    geNMABestMatch = geNMABestMatch.reset_index(drop=True)\n",
    "    \n",
    "    geXTrainBestMatch = geXTrain.copy()\n",
    "    geXTrainBestMatch = geXTrainBestMatch.reset_index()\n",
    "    geXTrainBestMatch = geXTrainBestMatch.reindex(best_match)\n",
    "    geXTrainBestMatch = geXTrainBestMatch.drop([\"index\"], axis=1)\n",
    "    geXTrainBestMatch = geXTrainBestMatch.reset_index(drop=True)\n",
    "    \n",
    "    return geNMABestMatch, geXTrainBestMatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5107042e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################################################\n",
      "Mean correlation:\n",
      "CMOT_Prediciton 0.9417681276907193\n",
      "MOFA+ 0.9350190797599628\n",
      "Seurat 0.9304362215383665\n",
      "\n",
      "\n",
      "Max correlation:\n",
      "CMOT_Prediction 0.9876488057167485\n",
      "MOFA+ 0.9911669964557466\n",
      "Seurat 0.9843790491273984\n",
      "\n",
      "\n",
      "Median correlation:\n",
      "CMOT_Prediction 0.94806473835396\n",
      "MOFA+ 0.9478044067772674\n",
      "Seurat 0.9424946649529214\n",
      "##################################################################################\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "append() takes exactly one argument (0 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeurat\u001b[39m\u001b[38;5;124m\"\u001b[39m,predCorrdf[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeurat\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\u001b[38;5;241m.\u001b[39mmedian()[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m##################################################################################\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 53\u001b[0m \u001b[43mmean\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: append() takes exactly one argument (0 given)"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=5)\n",
    "percent_align_n = 1\n",
    "mean = []\n",
    " \n",
    "topFeat=350\n",
    "k=200\n",
    "\n",
    "for train_index, test_index in skf.split(mod1, labels):\n",
    "    \n",
    "    X, X_hat = mod1.loc[train_index], mod1.loc[test_index]\n",
    "    Y, Y_hat = mod2.loc[train_index], mod2.loc[test_index]\n",
    "    \n",
    "    if labels is not None:\n",
    "        labelYTrain, labelYTest = labels.loc[train_index], labels.loc[test_index]\n",
    "    \n",
    "#     print (\"Aligning modalities ...\")\n",
    "    X_aligned,Y_aligned = align_samples(X,Y,percent_align_n,d=5,mu=0.5)\n",
    "    best_match = get_best_match(X_aligned,Y_aligned)\n",
    "    X_NMABestMatch, X_BestMatch = find_best_match_df(best_match,X_aligned, X)\n",
    "    \n",
    "#     clusterLabels = kmeans(X_NMABestMatch,Y_aligned)\n",
    "\n",
    "    # HERE Xs, ys, Xt are variables for OT i.e. Xs = Y, Xt = Y_hat, ys=known labels\n",
    "    Xs = Y.to_numpy()\n",
    "#     ys = clusterLabels[:len(Y)]\n",
    "    ys = labelYTrain.to_numpy()\n",
    "    Xt = Y_hat.to_numpy() \n",
    "    method = \"emd\"\n",
    "\n",
    "#     print (\"Starting Optimal transport using:\", method)\n",
    "    transp_Xs = optimal_transport(Xs,Xt,ys, method)\n",
    "\n",
    "#     print (\"Predicting phenotype ...\")\n",
    "    X_hat_pred = predict_phenotype(transp_Xs,Y_hat,X_BestMatch,ys,k,topFeat)\n",
    "    predtion_Corr=  check_correlation(X_hat_pred,X_hat)\n",
    "    print (\"##################################################################################\")\n",
    "    print (\"Mean correlation:\")\n",
    "    print ( \"CMOT_Prediciton\",pd.DataFrame(predtion_Corr, columns=[\"CMOT_Prediction\"]).mean()[0])\n",
    "    print (\"MOFA+\",predCorrdf[[\"MOFA+\"]].mean()[0])\n",
    "    print (\"Seurat\", predCorrdf[[\"Seurat\"]].mean()[0])\n",
    "    print (\"\\n\")\n",
    "    print (\"Max correlation:\")\n",
    "    print (\"CMOT_Prediction\", pd.DataFrame(predtion_Corr, columns=[\"CMOT_Prediction\"]).max()[0])\n",
    "    print (\"MOFA+\",predCorrdf[[\"MOFA+\"]].max()[0])\n",
    "    print (\"Seurat\",predCorrdf[[\"Seurat\"]].max()[0])\n",
    "    print (\"\\n\")\n",
    "    print (\"Median correlation:\")\n",
    "    print (\"CMOT_Prediction\",pd.DataFrame(predtion_Corr, columns=[\"CMOT_Prediction\"]).median()[0])\n",
    "    print (\"MOFA+\",predCorrdf[[\"MOFA+\"]].median()[0])\n",
    "    print (\"Seurat\",predCorrdf[[\"Seurat\"]].median()[0])\n",
    "    print (\"##################################################################################\")\n",
    "    \n",
    "    mean.append()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e64d1863",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9350190797599628"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predCorrdf[[\"MOFA+\"]].mean()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986bea48",
   "metadata": {},
   "source": [
    "#### Calculate Runtimes for CMOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c662e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed prediction!\n",
      "Total runtime: 2.1950278282165527\n"
     ]
    }
   ],
   "source": [
    "runtimes = []\n",
    "reg_e=5e03\n",
    "reg_cl=1e00\n",
    "percent_align_n = 1\n",
    "topFeat=50\n",
    "k=10\n",
    "\n",
    "\n",
    "for i in range(1):\n",
    "    start = time.time()\n",
    "#     X = mod1XTrain #GE\n",
    "#     Y = mod2XTrain #SNP\n",
    "#     X_hat = mod1XTest\n",
    "#     Y_hat = mod2XTest\n",
    "    \n",
    "    #FOR GE FROM SNP\n",
    "#     X = geXTrain \n",
    "#     Y = snpXTrain \n",
    "#     X_hat = geXTest\n",
    "#     Y_hat = snpXTest\n",
    "    \n",
    "    # FOR SNP FROM GE\n",
    "    X = snpXTrain #GE\n",
    "    Y = geXTrain #SNP\n",
    "    X_hat = snpXTest\n",
    "    Y_hat = geXTest\n",
    "    \n",
    "\n",
    "#     print (\"Aligning modalities ...\")\n",
    "    X_aligned,Y_aligned = align_samples(X,Y,percent_align_n,d=5,mu=0.5)\n",
    "    best_match = get_best_match(X_aligned,Y_aligned)\n",
    "    X_NMABestMatch, X_BestMatch = find_best_match_df(best_match,X_aligned, X)\n",
    "    \n",
    "    #MAKRE SURE TO CHANGE NUMBER OF CLUSTERS ACCORDING TO DATASET\n",
    "    hc = AgglomerativeClustering(n_clusters = 2, affinity = 'euclidean', linkage ='ward')\n",
    "    hclabels=hc.fit_predict(Y)\n",
    "    l = pd.DataFrame(hclabels, columns = [\"HC\"])\n",
    "\n",
    "    # HERE Xs, ys, Xt are variables for OT i.e. Xs = Y, Xt = Y_hat, ys=known labels\n",
    "    Xs = Y.to_numpy()\n",
    "#     ys = clusterLabels[:len(Y)]\n",
    "    ys = l[\"HC\"].to_numpy()\n",
    "    Xt = Y_hat.to_numpy() \n",
    "    method = \"lpl1_reg\"\n",
    "\n",
    "#     print (\"Starting Optimal transport using:\", method)\n",
    "    transp_Xs = optimal_transport(Xs,Xt,reg_e, reg_cl,ys, method)\n",
    "\n",
    "#     print (\"Predicting phenotype ...\")\n",
    "    X_hat_pred = predict_phenotype(transp_Xs,Y_hat,X_BestMatch,ys,k,topFeat)\n",
    "    predtion_Corr=  check_correlation(X_hat_pred,X_hat)\n",
    "    print (\"Completed prediction!\")\n",
    "    print (\"Total runtime:\",time.time()-start)\n",
    "    runtimes.append(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6683d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc4d3ad9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAMZUlEQVR4nO3df6hf913H8edr6Sqjlv1h5lWS0PSPDBbXbW6XVHSw6+ikpSNlDDUdAwvqnbDgpFqa4qja+UdbcfiH8UeQQf+ZWR1sXE1MBO0XUZkm1W6SxLqYdSRV3NrVunQ/ksjbP3IjX29v7v3e5vv93uSd5wMu3HPO59zP58K5zxxO+fakqpAkXftet94LkCSNh0GXpCYMuiQ1YdAlqQmDLklN3LBeE2/cuLG2bt26XtNLl/XKK69w0003rfcypGU9/fTTL1TVm5Y7tm5B37p1K0ePHl2v6aXLGgwGzM3NrfcypGUl+erljvnIRZKaMOiS1IRBl6QmDLokNWHQJakJgy5JTRh0SWrCoEtSE+v2wSJpWpJMZR7fLaD15h262quqNX3d8uCfrfkcY66rgUGXpCYMuiQ1YdAlqQmDLklNGHRJasKgS1ITBl2SmjDoktSEQZekJgy6JDVh0CWpCYMuSU2MFPQkdyZ5NsnJJHsuM+ankhxPcizJp8e7TEnSalb93+cm2QDsBd4HnAGOJFmoquNDY7YBDwE/VlUvJfn+SS1YkrS8Ue7QdwAnq+pUVZ0D9gP3LBnz88DeqnoJoKq+Nt5lSpJWM8oLLjYBp4e2zwC3LxnzZoAkfwtsAH69qg4t/UFJ5oF5gJmZGQaDwWtYsjR5Xpu6Fo3rjUU3ANuAOWAz8NdJbquq/xoeVFX7gH0As7OzNTc3N6bppTE6dACvTV2LRnnk8jywZWh78+K+YWeAhao6X1VfAf6Vi4GXJE3JKEE/AmxLcmuSG4FdwMKSMZ/n4t05STZy8RHMqfEtU5K0mlWDXlUXgN3AYeAE8GRVHUvySJKdi8MOAy8mOQ48BTxQVS9OatGSpFcb6Rl6VR0EDi7Z9/DQ9wXcv/glSVoHflJUkpow6JLUhEGXpCYMuiQ1YdAlqQmDLklNGHRJasKgS1ITBl2SmjDoktSEQZekJgy6JDVh0CWpiXG9sUiairf/xl/w8rfPT3yerXsOTHyON77h9Xzx135i4vPo+mHQdU15+dvnee7Ruyc6x2AwmMor6Kbxj4auLz5ykaQmDLokNWHQJakJgy5JTRh0SWrCoEtSEwZdkpow6JLUhEGXpCYMuiQ1YdAlqQmDLklNGHRJasKgS1ITBl2SmjDoktTESEFPcmeSZ5OcTLJnmeP3Jfl6kmcWv35u/EuVJK1k1TcWJdkA7AXeB5wBjiRZqKrjS4Z+pqp2T2CNkqQRjHKHvgM4WVWnquocsB+4Z7LLkiSt1ShB3wScHto+s7hvqQ8m+VKSzybZMpbVSZJGNq6XRP8p8MdV9d0kHwGeAN67dFCSeWAeYGZmhsFgMKbpdT2Z9HVz9uzZqV2b/g1onEYJ+vPA8B335sV9/6eqXhza/CPg8eV+UFXtA/YBzM7O1jTerK5mDh1g0tfNYDCY+BzAVH4XXV9GeeRyBNiW5NYkNwK7gIXhAUl+cGhzJ3BifEuUJI1i1Tv0qrqQZDdwGNgAfKqqjiV5BDhaVQvALybZCVwAvgHcN8E1S5KWMdIz9Ko6CBxcsu/hoe8fAh4a79IkSWvhJ0UlqQmDLklNGHRJasKgS1ITBl2SmjDoktSEQZekJgy6JDVh0CWpCYMuSU0YdElqwqBLUhMGXZKaMOiS1IRBl6QmDLokNWHQJakJgy5JTRh0SWrCoEtSEwZdkpow6JLUhEGXpCYMuiQ1YdAlqQmDLklNGHRJasKgS1ITBl2SmjDoktSEQZekJgy6JDUxUtCT3Jnk2SQnk+xZYdwHk1SS2fEtUZI0ilWDnmQDsBe4C9gO3Jtk+zLjbgY+Bvz9uBcpSVrdKHfoO4CTVXWqqs4B+4F7lhn3CeAx4DtjXJ8kaUQ3jDBmE3B6aPsMcPvwgCTvBLZU1YEkD1zuByWZB+YBZmZmGAwGa16wNOnr5uzZs1O7Nv0b0DiNEvQVJXkd8EngvtXGVtU+YB/A7Oxszc3NXen0ut4cOsCkr5vBYDDxOYCp/C66vozyyOV5YMvQ9ubFfZfcDLwVGCR5DvgRYMH/MCpJ0zVK0I8A25LcmuRGYBewcOlgVb1cVRuramtVbQW+AOysqqMTWbEkaVmrBr2qLgC7gcPACeDJqjqW5JEkOye9QEnSaEZ6hl5VB4GDS/Y9fJmxc1e+LEnSWvlJUUlqwqBLUhMGXZKaMOiS1IRBl6QmDLokNWHQJakJgy5JTRh0SWrCoEtSEwZdkpow6JLUhEGXpCYMuiQ1YdAlqYkrfqeoNE03v2UPtz2xZ/ITPTH5KW5+C8Ddk59I1w2DrmvKN088ynOPTjaC03pJ9NY9ByY+h64vPnKRpCYMuiQ1YdAlqQmDLklNGHRJasKgS1ITBl2SmjDoktSEQZekJgy6JDVh0CWpCYMuSU0YdElqwqBLUhMGXZKaGCnoSe5M8mySk0le9XaBJL+Q5J+TPJPkb5JsH/9SJUkrWTXoSTYAe4G7gO3AvcsE+9NVdVtVvQN4HPjkuBcqSVrZKHfoO4CTVXWqqs4B+4F7hgdU1X8Pbd4E1PiWKEkaxSivoNsEnB7aPgPcvnRQko8C9wM3Au9d7gclmQfmAWZmZhgMBmtcrsTEr5uzZ89O7dr0b0DjNLZ3ilbVXmBvkg8BHwd+Zpkx+4B9ALOzszWN9zaqmUMHJv6+z2m9U3Qav4uuL6ME/Xlgy9D25sV9l7Mf+P0rWZS0kqm8XPnQ5Od44xteP/E5dH0ZJehHgG1JbuViyHcBHxoekGRbVX15cfNu4MtIE/Dco3dPfI6tew5MZR5p3FYNelVdSLIbOAxsAD5VVceSPAIcraoFYHeSO4DzwEss87hFkjRZIz1Dr6qDwMEl+x4e+v5jY16XJGmN/KSoJDVh0CWpCYMuSU0YdElqwqBLUhMGXZKaMOiS1IRBl6QmDLokNWHQJakJgy5JTRh0SWrCoEtSEwZdkpow6JLUhEGXpCYMuiQ1YdAlqQmDLklNGHRJasKgS1ITBl2SmjDoktSEQZekJgy6JDVh0CWpCYMuSU0YdElqwqBLUhMGXZKaMOiS1MRIQU9yZ5Jnk5xMsmeZ4/cnOZ7kS0n+Mskt41+qJGklqwY9yQZgL3AXsB24N8n2JcP+CZitqrcBnwUeH/dCJUkrG+UOfQdwsqpOVdU5YD9wz/CAqnqqqr61uPkFYPN4lylJWs0NI4zZBJwe2j4D3L7C+J8F/ny5A0nmgXmAmZkZBoPBaKuUpsxrU9eiUYI+siQfBmaB9yx3vKr2AfsAZmdna25ubpzTS+Nx6ABem7oWjRL054EtQ9ubF/f9P0nuAH4VeE9VfXc8y5MkjWqUZ+hHgG1Jbk1yI7ALWBgekOSHgT8EdlbV18a/TEnSalYNelVdAHYDh4ETwJNVdSzJI0l2Lg77LeB7gT9J8kyShcv8OEnShIz0DL2qDgIHl+x7eOj7O8a8LknSGvlJUUlqwqBLUhMGXZKaMOiS1IRBl6QmDLokNWHQJakJgy5JTRh0SWrCoEtSEwZdkpow6JLUhEGXpCbG+sYi6WqUZO3nPLb2eapq7SdJY+QdutqrqjV9PfXUU2s+x5jramDQJakJgy5JTRh0SWrCoEtSEwZdkpow6JLUhEGXpCYMuiQ1kfX6QESSrwNfXZfJpZVtBF5Y70VIl3FLVb1puQPrFnTpapXkaFXNrvc6pLXykYskNWHQJakJgy692r71XoD0WvgMXZKa8A5dkpow6JLUhEFXa0l+IMn+JP+W5OkkB5O8OUkl+c2hcRuTnE/yu0P75pP8y+LXPyR59+L+zyV5JsnJJC8vfv9Mkh9dj99RusRX0KmtXHz33OeAJ6pq1+K+twMzwFeAu4GPLw7/SeDY0LnvBz4CvLuqXkjyTuDzSXZU1QcWx8wBv1JV75/ObyStzDt0dfbjwPmq+oNLO6rqi8Bp4FvAiSSXPkD008CTQ+c+CDxQVS8snvePwBPAR6excOm1MOjq7K3A0ysc3w/sSrIF+B/g34eO/dAy5x5d3C9dlXzkouvZIeATwH8Cn1nntUhXzDt0dXYMeNflDlbVOS7ehf8y8Nklh48vc+67GHrOLl1tDLo6+yvge5LMX9qR5G3AlqExvw08WFXfWHLu48BjSb5v8bx3APcBvzfJBUtXwkcuaquqKskHgN9J8iDwHeA54JeGxhxjmbvuqlpIsgn4uyQFfBP4cFX9xzTWLr0WfvRfkprwkYskNWHQJakJgy5JTRh0SWrCoEtSEwZdkpow6JLUxP8CRPVZ8SyMwCgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(predtion_Corr, columns=[\"CMOT\"]).boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c61b3a03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.16"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_time = sum(runtimes)/len(runtimes)\n",
    "round(avg_time,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f170c4c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MBP</th>\n",
       "      <th>GFAP</th>\n",
       "      <th>MT3</th>\n",
       "      <th>NRGN</th>\n",
       "      <th>CLU</th>\n",
       "      <th>PTGDS</th>\n",
       "      <th>FTL</th>\n",
       "      <th>SNAP25</th>\n",
       "      <th>ALDOA</th>\n",
       "      <th>TUBA1B</th>\n",
       "      <th>...</th>\n",
       "      <th>KCNJ4</th>\n",
       "      <th>CNN3</th>\n",
       "      <th>MRPL55</th>\n",
       "      <th>PSMC5</th>\n",
       "      <th>GNAO1</th>\n",
       "      <th>PRKACB</th>\n",
       "      <th>RGCC</th>\n",
       "      <th>BIN1</th>\n",
       "      <th>NDUFA8</th>\n",
       "      <th>NCALD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.215962</td>\n",
       "      <td>0.221578</td>\n",
       "      <td>0.246075</td>\n",
       "      <td>0.13982</td>\n",
       "      <td>0.235637</td>\n",
       "      <td>0.163181</td>\n",
       "      <td>0.156388</td>\n",
       "      <td>0.060474</td>\n",
       "      <td>0.11207</td>\n",
       "      <td>0.092219</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004927</td>\n",
       "      <td>0.004929</td>\n",
       "      <td>0.007212</td>\n",
       "      <td>0.010926</td>\n",
       "      <td>0.00991</td>\n",
       "      <td>0.004103</td>\n",
       "      <td>0.005752</td>\n",
       "      <td>0.012232</td>\n",
       "      <td>0.008097</td>\n",
       "      <td>0.003337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.221621</td>\n",
       "      <td>0.230604</td>\n",
       "      <td>0.248126</td>\n",
       "      <td>0.13064</td>\n",
       "      <td>0.235455</td>\n",
       "      <td>0.159403</td>\n",
       "      <td>0.160334</td>\n",
       "      <td>0.060821</td>\n",
       "      <td>0.106623</td>\n",
       "      <td>0.091247</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004687</td>\n",
       "      <td>0.005183</td>\n",
       "      <td>0.006918</td>\n",
       "      <td>0.011028</td>\n",
       "      <td>0.009602</td>\n",
       "      <td>0.004183</td>\n",
       "      <td>0.005903</td>\n",
       "      <td>0.011984</td>\n",
       "      <td>0.008185</td>\n",
       "      <td>0.003196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.218238</td>\n",
       "      <td>0.222344</td>\n",
       "      <td>0.246689</td>\n",
       "      <td>0.140295</td>\n",
       "      <td>0.233608</td>\n",
       "      <td>0.163468</td>\n",
       "      <td>0.156773</td>\n",
       "      <td>0.060363</td>\n",
       "      <td>0.112151</td>\n",
       "      <td>0.091829</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00494</td>\n",
       "      <td>0.004875</td>\n",
       "      <td>0.007271</td>\n",
       "      <td>0.010946</td>\n",
       "      <td>0.009829</td>\n",
       "      <td>0.004056</td>\n",
       "      <td>0.005731</td>\n",
       "      <td>0.01227</td>\n",
       "      <td>0.008109</td>\n",
       "      <td>0.003324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.189445</td>\n",
       "      <td>0.208594</td>\n",
       "      <td>0.22955</td>\n",
       "      <td>0.155812</td>\n",
       "      <td>0.237425</td>\n",
       "      <td>0.158335</td>\n",
       "      <td>0.145403</td>\n",
       "      <td>0.072136</td>\n",
       "      <td>0.124424</td>\n",
       "      <td>0.10266</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005577</td>\n",
       "      <td>0.004755</td>\n",
       "      <td>0.007735</td>\n",
       "      <td>0.011442</td>\n",
       "      <td>0.010549</td>\n",
       "      <td>0.004613</td>\n",
       "      <td>0.005309</td>\n",
       "      <td>0.012325</td>\n",
       "      <td>0.008715</td>\n",
       "      <td>0.004008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.217178</td>\n",
       "      <td>0.221919</td>\n",
       "      <td>0.246266</td>\n",
       "      <td>0.140143</td>\n",
       "      <td>0.234728</td>\n",
       "      <td>0.163801</td>\n",
       "      <td>0.15657</td>\n",
       "      <td>0.060388</td>\n",
       "      <td>0.111889</td>\n",
       "      <td>0.092137</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004945</td>\n",
       "      <td>0.004918</td>\n",
       "      <td>0.00723</td>\n",
       "      <td>0.010943</td>\n",
       "      <td>0.00989</td>\n",
       "      <td>0.004079</td>\n",
       "      <td>0.005749</td>\n",
       "      <td>0.012255</td>\n",
       "      <td>0.008111</td>\n",
       "      <td>0.003329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.218565</td>\n",
       "      <td>0.222034</td>\n",
       "      <td>0.246812</td>\n",
       "      <td>0.140923</td>\n",
       "      <td>0.23407</td>\n",
       "      <td>0.163739</td>\n",
       "      <td>0.157119</td>\n",
       "      <td>0.060779</td>\n",
       "      <td>0.111923</td>\n",
       "      <td>0.092322</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004975</td>\n",
       "      <td>0.004939</td>\n",
       "      <td>0.007273</td>\n",
       "      <td>0.010953</td>\n",
       "      <td>0.009886</td>\n",
       "      <td>0.004088</td>\n",
       "      <td>0.005762</td>\n",
       "      <td>0.01228</td>\n",
       "      <td>0.008149</td>\n",
       "      <td>0.003367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.216958</td>\n",
       "      <td>0.222568</td>\n",
       "      <td>0.24695</td>\n",
       "      <td>0.140584</td>\n",
       "      <td>0.236033</td>\n",
       "      <td>0.163519</td>\n",
       "      <td>0.156932</td>\n",
       "      <td>0.060683</td>\n",
       "      <td>0.112281</td>\n",
       "      <td>0.092772</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004976</td>\n",
       "      <td>0.004949</td>\n",
       "      <td>0.007241</td>\n",
       "      <td>0.01096</td>\n",
       "      <td>0.009974</td>\n",
       "      <td>0.004117</td>\n",
       "      <td>0.005786</td>\n",
       "      <td>0.012298</td>\n",
       "      <td>0.008145</td>\n",
       "      <td>0.003359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.213821</td>\n",
       "      <td>0.211425</td>\n",
       "      <td>0.238745</td>\n",
       "      <td>0.146705</td>\n",
       "      <td>0.234646</td>\n",
       "      <td>0.159277</td>\n",
       "      <td>0.152392</td>\n",
       "      <td>0.066765</td>\n",
       "      <td>0.116888</td>\n",
       "      <td>0.097319</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00519</td>\n",
       "      <td>0.004779</td>\n",
       "      <td>0.007333</td>\n",
       "      <td>0.011101</td>\n",
       "      <td>0.010275</td>\n",
       "      <td>0.004413</td>\n",
       "      <td>0.005535</td>\n",
       "      <td>0.012199</td>\n",
       "      <td>0.008355</td>\n",
       "      <td>0.003788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.18616</td>\n",
       "      <td>0.207896</td>\n",
       "      <td>0.230321</td>\n",
       "      <td>0.157334</td>\n",
       "      <td>0.238795</td>\n",
       "      <td>0.159067</td>\n",
       "      <td>0.14454</td>\n",
       "      <td>0.072538</td>\n",
       "      <td>0.125258</td>\n",
       "      <td>0.103259</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005615</td>\n",
       "      <td>0.00475</td>\n",
       "      <td>0.007791</td>\n",
       "      <td>0.011468</td>\n",
       "      <td>0.010606</td>\n",
       "      <td>0.004625</td>\n",
       "      <td>0.005313</td>\n",
       "      <td>0.012352</td>\n",
       "      <td>0.008739</td>\n",
       "      <td>0.004031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.217619</td>\n",
       "      <td>0.223081</td>\n",
       "      <td>0.247043</td>\n",
       "      <td>0.14055</td>\n",
       "      <td>0.235746</td>\n",
       "      <td>0.163619</td>\n",
       "      <td>0.1568</td>\n",
       "      <td>0.060671</td>\n",
       "      <td>0.112275</td>\n",
       "      <td>0.092694</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004966</td>\n",
       "      <td>0.004943</td>\n",
       "      <td>0.007247</td>\n",
       "      <td>0.010958</td>\n",
       "      <td>0.009952</td>\n",
       "      <td>0.004116</td>\n",
       "      <td>0.005803</td>\n",
       "      <td>0.012311</td>\n",
       "      <td>0.008143</td>\n",
       "      <td>0.003346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.217004</td>\n",
       "      <td>0.224145</td>\n",
       "      <td>0.243915</td>\n",
       "      <td>0.134906</td>\n",
       "      <td>0.234317</td>\n",
       "      <td>0.161318</td>\n",
       "      <td>0.154979</td>\n",
       "      <td>0.06185</td>\n",
       "      <td>0.109186</td>\n",
       "      <td>0.090607</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004767</td>\n",
       "      <td>0.005105</td>\n",
       "      <td>0.007052</td>\n",
       "      <td>0.010986</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.004259</td>\n",
       "      <td>0.005817</td>\n",
       "      <td>0.012103</td>\n",
       "      <td>0.008129</td>\n",
       "      <td>0.003294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.212212</td>\n",
       "      <td>0.208201</td>\n",
       "      <td>0.236558</td>\n",
       "      <td>0.147034</td>\n",
       "      <td>0.233769</td>\n",
       "      <td>0.158871</td>\n",
       "      <td>0.151534</td>\n",
       "      <td>0.067127</td>\n",
       "      <td>0.117201</td>\n",
       "      <td>0.097162</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005198</td>\n",
       "      <td>0.004764</td>\n",
       "      <td>0.007355</td>\n",
       "      <td>0.011137</td>\n",
       "      <td>0.010256</td>\n",
       "      <td>0.004419</td>\n",
       "      <td>0.00552</td>\n",
       "      <td>0.012155</td>\n",
       "      <td>0.008357</td>\n",
       "      <td>0.003799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.186316</td>\n",
       "      <td>0.207945</td>\n",
       "      <td>0.230499</td>\n",
       "      <td>0.157621</td>\n",
       "      <td>0.238985</td>\n",
       "      <td>0.159405</td>\n",
       "      <td>0.144455</td>\n",
       "      <td>0.072637</td>\n",
       "      <td>0.125469</td>\n",
       "      <td>0.103257</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005625</td>\n",
       "      <td>0.004754</td>\n",
       "      <td>0.007807</td>\n",
       "      <td>0.011478</td>\n",
       "      <td>0.010627</td>\n",
       "      <td>0.004628</td>\n",
       "      <td>0.005308</td>\n",
       "      <td>0.012398</td>\n",
       "      <td>0.008751</td>\n",
       "      <td>0.00403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.185475</td>\n",
       "      <td>0.208583</td>\n",
       "      <td>0.232269</td>\n",
       "      <td>0.15722</td>\n",
       "      <td>0.238632</td>\n",
       "      <td>0.159465</td>\n",
       "      <td>0.145259</td>\n",
       "      <td>0.072411</td>\n",
       "      <td>0.125046</td>\n",
       "      <td>0.10317</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005617</td>\n",
       "      <td>0.004763</td>\n",
       "      <td>0.007797</td>\n",
       "      <td>0.011493</td>\n",
       "      <td>0.010584</td>\n",
       "      <td>0.004626</td>\n",
       "      <td>0.00533</td>\n",
       "      <td>0.012367</td>\n",
       "      <td>0.008737</td>\n",
       "      <td>0.004031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.217011</td>\n",
       "      <td>0.222662</td>\n",
       "      <td>0.246914</td>\n",
       "      <td>0.139946</td>\n",
       "      <td>0.234904</td>\n",
       "      <td>0.163797</td>\n",
       "      <td>0.156816</td>\n",
       "      <td>0.060162</td>\n",
       "      <td>0.112011</td>\n",
       "      <td>0.091605</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004939</td>\n",
       "      <td>0.004905</td>\n",
       "      <td>0.007253</td>\n",
       "      <td>0.010945</td>\n",
       "      <td>0.009864</td>\n",
       "      <td>0.004063</td>\n",
       "      <td>0.00574</td>\n",
       "      <td>0.012255</td>\n",
       "      <td>0.008089</td>\n",
       "      <td>0.003288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.217718</td>\n",
       "      <td>0.222919</td>\n",
       "      <td>0.247101</td>\n",
       "      <td>0.140358</td>\n",
       "      <td>0.235108</td>\n",
       "      <td>0.163522</td>\n",
       "      <td>0.157093</td>\n",
       "      <td>0.060702</td>\n",
       "      <td>0.112094</td>\n",
       "      <td>0.092685</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004945</td>\n",
       "      <td>0.004951</td>\n",
       "      <td>0.007254</td>\n",
       "      <td>0.010941</td>\n",
       "      <td>0.009918</td>\n",
       "      <td>0.004113</td>\n",
       "      <td>0.005784</td>\n",
       "      <td>0.012277</td>\n",
       "      <td>0.008122</td>\n",
       "      <td>0.003351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.175585</td>\n",
       "      <td>0.206208</td>\n",
       "      <td>0.224314</td>\n",
       "      <td>0.154597</td>\n",
       "      <td>0.239964</td>\n",
       "      <td>0.152937</td>\n",
       "      <td>0.143101</td>\n",
       "      <td>0.078414</td>\n",
       "      <td>0.125411</td>\n",
       "      <td>0.107003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005631</td>\n",
       "      <td>0.004869</td>\n",
       "      <td>0.00768</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.010626</td>\n",
       "      <td>0.004981</td>\n",
       "      <td>0.00522</td>\n",
       "      <td>0.012096</td>\n",
       "      <td>0.009062</td>\n",
       "      <td>0.004223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.217602</td>\n",
       "      <td>0.221761</td>\n",
       "      <td>0.246306</td>\n",
       "      <td>0.139853</td>\n",
       "      <td>0.23441</td>\n",
       "      <td>0.163708</td>\n",
       "      <td>0.156507</td>\n",
       "      <td>0.060259</td>\n",
       "      <td>0.112045</td>\n",
       "      <td>0.091654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004927</td>\n",
       "      <td>0.004876</td>\n",
       "      <td>0.007239</td>\n",
       "      <td>0.010931</td>\n",
       "      <td>0.009847</td>\n",
       "      <td>0.004054</td>\n",
       "      <td>0.005747</td>\n",
       "      <td>0.012236</td>\n",
       "      <td>0.008096</td>\n",
       "      <td>0.003309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.216709</td>\n",
       "      <td>0.221875</td>\n",
       "      <td>0.246619</td>\n",
       "      <td>0.140227</td>\n",
       "      <td>0.234581</td>\n",
       "      <td>0.163465</td>\n",
       "      <td>0.156519</td>\n",
       "      <td>0.06015</td>\n",
       "      <td>0.11177</td>\n",
       "      <td>0.092206</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004941</td>\n",
       "      <td>0.004924</td>\n",
       "      <td>0.007234</td>\n",
       "      <td>0.010921</td>\n",
       "      <td>0.009873</td>\n",
       "      <td>0.004074</td>\n",
       "      <td>0.005757</td>\n",
       "      <td>0.01224</td>\n",
       "      <td>0.008115</td>\n",
       "      <td>0.003327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.220416</td>\n",
       "      <td>0.229572</td>\n",
       "      <td>0.246966</td>\n",
       "      <td>0.129964</td>\n",
       "      <td>0.235547</td>\n",
       "      <td>0.158967</td>\n",
       "      <td>0.159766</td>\n",
       "      <td>0.06063</td>\n",
       "      <td>0.106425</td>\n",
       "      <td>0.091032</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004654</td>\n",
       "      <td>0.005162</td>\n",
       "      <td>0.006872</td>\n",
       "      <td>0.010999</td>\n",
       "      <td>0.009598</td>\n",
       "      <td>0.00418</td>\n",
       "      <td>0.005878</td>\n",
       "      <td>0.011942</td>\n",
       "      <td>0.00816</td>\n",
       "      <td>0.003184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.187308</td>\n",
       "      <td>0.208056</td>\n",
       "      <td>0.229855</td>\n",
       "      <td>0.156334</td>\n",
       "      <td>0.238105</td>\n",
       "      <td>0.157781</td>\n",
       "      <td>0.145339</td>\n",
       "      <td>0.07234</td>\n",
       "      <td>0.124763</td>\n",
       "      <td>0.102994</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005611</td>\n",
       "      <td>0.004738</td>\n",
       "      <td>0.007759</td>\n",
       "      <td>0.011456</td>\n",
       "      <td>0.010539</td>\n",
       "      <td>0.004635</td>\n",
       "      <td>0.005392</td>\n",
       "      <td>0.012335</td>\n",
       "      <td>0.008724</td>\n",
       "      <td>0.004035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.218006</td>\n",
       "      <td>0.221368</td>\n",
       "      <td>0.246003</td>\n",
       "      <td>0.140753</td>\n",
       "      <td>0.233117</td>\n",
       "      <td>0.163269</td>\n",
       "      <td>0.156667</td>\n",
       "      <td>0.060886</td>\n",
       "      <td>0.112327</td>\n",
       "      <td>0.092278</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004976</td>\n",
       "      <td>0.004906</td>\n",
       "      <td>0.007274</td>\n",
       "      <td>0.010943</td>\n",
       "      <td>0.009883</td>\n",
       "      <td>0.004094</td>\n",
       "      <td>0.00574</td>\n",
       "      <td>0.012261</td>\n",
       "      <td>0.008131</td>\n",
       "      <td>0.003389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.21747</td>\n",
       "      <td>0.222622</td>\n",
       "      <td>0.247031</td>\n",
       "      <td>0.140342</td>\n",
       "      <td>0.235051</td>\n",
       "      <td>0.163601</td>\n",
       "      <td>0.157074</td>\n",
       "      <td>0.060084</td>\n",
       "      <td>0.111522</td>\n",
       "      <td>0.092419</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004944</td>\n",
       "      <td>0.00495</td>\n",
       "      <td>0.007241</td>\n",
       "      <td>0.010939</td>\n",
       "      <td>0.009896</td>\n",
       "      <td>0.004073</td>\n",
       "      <td>0.005746</td>\n",
       "      <td>0.012274</td>\n",
       "      <td>0.008117</td>\n",
       "      <td>0.003316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.218414</td>\n",
       "      <td>0.222164</td>\n",
       "      <td>0.246992</td>\n",
       "      <td>0.140515</td>\n",
       "      <td>0.23476</td>\n",
       "      <td>0.163813</td>\n",
       "      <td>0.157031</td>\n",
       "      <td>0.06035</td>\n",
       "      <td>0.111656</td>\n",
       "      <td>0.092123</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004967</td>\n",
       "      <td>0.004945</td>\n",
       "      <td>0.007249</td>\n",
       "      <td>0.010934</td>\n",
       "      <td>0.009893</td>\n",
       "      <td>0.004063</td>\n",
       "      <td>0.005782</td>\n",
       "      <td>0.012265</td>\n",
       "      <td>0.008124</td>\n",
       "      <td>0.003322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.218624</td>\n",
       "      <td>0.222714</td>\n",
       "      <td>0.24733</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.235121</td>\n",
       "      <td>0.164123</td>\n",
       "      <td>0.157138</td>\n",
       "      <td>0.060598</td>\n",
       "      <td>0.111796</td>\n",
       "      <td>0.092101</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004972</td>\n",
       "      <td>0.004955</td>\n",
       "      <td>0.007258</td>\n",
       "      <td>0.010965</td>\n",
       "      <td>0.009913</td>\n",
       "      <td>0.004071</td>\n",
       "      <td>0.005815</td>\n",
       "      <td>0.012279</td>\n",
       "      <td>0.008139</td>\n",
       "      <td>0.003327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.191404</td>\n",
       "      <td>0.207009</td>\n",
       "      <td>0.230608</td>\n",
       "      <td>0.156687</td>\n",
       "      <td>0.236977</td>\n",
       "      <td>0.158064</td>\n",
       "      <td>0.147038</td>\n",
       "      <td>0.072446</td>\n",
       "      <td>0.124659</td>\n",
       "      <td>0.10305</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005604</td>\n",
       "      <td>0.004719</td>\n",
       "      <td>0.007776</td>\n",
       "      <td>0.011477</td>\n",
       "      <td>0.010545</td>\n",
       "      <td>0.004632</td>\n",
       "      <td>0.00535</td>\n",
       "      <td>0.01241</td>\n",
       "      <td>0.008724</td>\n",
       "      <td>0.004032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.218553</td>\n",
       "      <td>0.223069</td>\n",
       "      <td>0.248091</td>\n",
       "      <td>0.140983</td>\n",
       "      <td>0.235624</td>\n",
       "      <td>0.164665</td>\n",
       "      <td>0.157587</td>\n",
       "      <td>0.060493</td>\n",
       "      <td>0.112127</td>\n",
       "      <td>0.092484</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004966</td>\n",
       "      <td>0.004944</td>\n",
       "      <td>0.007262</td>\n",
       "      <td>0.010973</td>\n",
       "      <td>0.009912</td>\n",
       "      <td>0.004093</td>\n",
       "      <td>0.005773</td>\n",
       "      <td>0.01229</td>\n",
       "      <td>0.008159</td>\n",
       "      <td>0.003352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.176662</td>\n",
       "      <td>0.20898</td>\n",
       "      <td>0.224341</td>\n",
       "      <td>0.155148</td>\n",
       "      <td>0.241427</td>\n",
       "      <td>0.151939</td>\n",
       "      <td>0.143133</td>\n",
       "      <td>0.078819</td>\n",
       "      <td>0.126118</td>\n",
       "      <td>0.107406</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005672</td>\n",
       "      <td>0.004914</td>\n",
       "      <td>0.007713</td>\n",
       "      <td>0.011849</td>\n",
       "      <td>0.010634</td>\n",
       "      <td>0.005018</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>0.012169</td>\n",
       "      <td>0.009101</td>\n",
       "      <td>0.004253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.217397</td>\n",
       "      <td>0.222344</td>\n",
       "      <td>0.246385</td>\n",
       "      <td>0.140256</td>\n",
       "      <td>0.23439</td>\n",
       "      <td>0.1638</td>\n",
       "      <td>0.156715</td>\n",
       "      <td>0.060291</td>\n",
       "      <td>0.111957</td>\n",
       "      <td>0.091619</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004939</td>\n",
       "      <td>0.004891</td>\n",
       "      <td>0.00725</td>\n",
       "      <td>0.010926</td>\n",
       "      <td>0.009845</td>\n",
       "      <td>0.004065</td>\n",
       "      <td>0.005723</td>\n",
       "      <td>0.012249</td>\n",
       "      <td>0.008093</td>\n",
       "      <td>0.003324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.217425</td>\n",
       "      <td>0.221991</td>\n",
       "      <td>0.246316</td>\n",
       "      <td>0.140556</td>\n",
       "      <td>0.235053</td>\n",
       "      <td>0.16296</td>\n",
       "      <td>0.156689</td>\n",
       "      <td>0.060639</td>\n",
       "      <td>0.111964</td>\n",
       "      <td>0.092781</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004943</td>\n",
       "      <td>0.004944</td>\n",
       "      <td>0.007239</td>\n",
       "      <td>0.010961</td>\n",
       "      <td>0.00994</td>\n",
       "      <td>0.004111</td>\n",
       "      <td>0.005759</td>\n",
       "      <td>0.012269</td>\n",
       "      <td>0.008138</td>\n",
       "      <td>0.003364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.184646</td>\n",
       "      <td>0.208264</td>\n",
       "      <td>0.230932</td>\n",
       "      <td>0.156379</td>\n",
       "      <td>0.238795</td>\n",
       "      <td>0.158747</td>\n",
       "      <td>0.145681</td>\n",
       "      <td>0.072181</td>\n",
       "      <td>0.124539</td>\n",
       "      <td>0.102942</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005599</td>\n",
       "      <td>0.004755</td>\n",
       "      <td>0.007763</td>\n",
       "      <td>0.011443</td>\n",
       "      <td>0.010544</td>\n",
       "      <td>0.004628</td>\n",
       "      <td>0.005421</td>\n",
       "      <td>0.012336</td>\n",
       "      <td>0.00872</td>\n",
       "      <td>0.004032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.218143</td>\n",
       "      <td>0.221959</td>\n",
       "      <td>0.246876</td>\n",
       "      <td>0.140444</td>\n",
       "      <td>0.234075</td>\n",
       "      <td>0.163704</td>\n",
       "      <td>0.156746</td>\n",
       "      <td>0.060027</td>\n",
       "      <td>0.111635</td>\n",
       "      <td>0.091773</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004945</td>\n",
       "      <td>0.004913</td>\n",
       "      <td>0.007243</td>\n",
       "      <td>0.010921</td>\n",
       "      <td>0.009842</td>\n",
       "      <td>0.004044</td>\n",
       "      <td>0.005767</td>\n",
       "      <td>0.012265</td>\n",
       "      <td>0.00811</td>\n",
       "      <td>0.003293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.217511</td>\n",
       "      <td>0.223377</td>\n",
       "      <td>0.246721</td>\n",
       "      <td>0.139682</td>\n",
       "      <td>0.235083</td>\n",
       "      <td>0.16356</td>\n",
       "      <td>0.157278</td>\n",
       "      <td>0.060025</td>\n",
       "      <td>0.111726</td>\n",
       "      <td>0.091692</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004932</td>\n",
       "      <td>0.004937</td>\n",
       "      <td>0.007232</td>\n",
       "      <td>0.010937</td>\n",
       "      <td>0.009866</td>\n",
       "      <td>0.004061</td>\n",
       "      <td>0.005745</td>\n",
       "      <td>0.012248</td>\n",
       "      <td>0.008093</td>\n",
       "      <td>0.003298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.217397</td>\n",
       "      <td>0.221411</td>\n",
       "      <td>0.246461</td>\n",
       "      <td>0.14062</td>\n",
       "      <td>0.233459</td>\n",
       "      <td>0.163029</td>\n",
       "      <td>0.156369</td>\n",
       "      <td>0.0604</td>\n",
       "      <td>0.111901</td>\n",
       "      <td>0.092284</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004954</td>\n",
       "      <td>0.004892</td>\n",
       "      <td>0.007267</td>\n",
       "      <td>0.010929</td>\n",
       "      <td>0.009869</td>\n",
       "      <td>0.004077</td>\n",
       "      <td>0.005755</td>\n",
       "      <td>0.012259</td>\n",
       "      <td>0.008135</td>\n",
       "      <td>0.003342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.216363</td>\n",
       "      <td>0.221941</td>\n",
       "      <td>0.24662</td>\n",
       "      <td>0.139872</td>\n",
       "      <td>0.235789</td>\n",
       "      <td>0.163075</td>\n",
       "      <td>0.156567</td>\n",
       "      <td>0.059977</td>\n",
       "      <td>0.111902</td>\n",
       "      <td>0.092144</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004925</td>\n",
       "      <td>0.004911</td>\n",
       "      <td>0.007211</td>\n",
       "      <td>0.010936</td>\n",
       "      <td>0.009879</td>\n",
       "      <td>0.004067</td>\n",
       "      <td>0.005755</td>\n",
       "      <td>0.012232</td>\n",
       "      <td>0.008086</td>\n",
       "      <td>0.003307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.222114</td>\n",
       "      <td>0.246239</td>\n",
       "      <td>0.140195</td>\n",
       "      <td>0.233962</td>\n",
       "      <td>0.163045</td>\n",
       "      <td>0.156546</td>\n",
       "      <td>0.060506</td>\n",
       "      <td>0.111791</td>\n",
       "      <td>0.092229</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004944</td>\n",
       "      <td>0.00492</td>\n",
       "      <td>0.007248</td>\n",
       "      <td>0.010913</td>\n",
       "      <td>0.009868</td>\n",
       "      <td>0.004091</td>\n",
       "      <td>0.005753</td>\n",
       "      <td>0.01224</td>\n",
       "      <td>0.008111</td>\n",
       "      <td>0.003336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.215493</td>\n",
       "      <td>0.227</td>\n",
       "      <td>0.235861</td>\n",
       "      <td>0.141906</td>\n",
       "      <td>0.235974</td>\n",
       "      <td>0.157988</td>\n",
       "      <td>0.153508</td>\n",
       "      <td>0.065001</td>\n",
       "      <td>0.114768</td>\n",
       "      <td>0.094234</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005023</td>\n",
       "      <td>0.004891</td>\n",
       "      <td>0.007183</td>\n",
       "      <td>0.010948</td>\n",
       "      <td>0.010106</td>\n",
       "      <td>0.004324</td>\n",
       "      <td>0.005536</td>\n",
       "      <td>0.012043</td>\n",
       "      <td>0.008191</td>\n",
       "      <td>0.003684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.217102</td>\n",
       "      <td>0.222135</td>\n",
       "      <td>0.245988</td>\n",
       "      <td>0.139989</td>\n",
       "      <td>0.235293</td>\n",
       "      <td>0.163433</td>\n",
       "      <td>0.156346</td>\n",
       "      <td>0.060664</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.092401</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004948</td>\n",
       "      <td>0.004933</td>\n",
       "      <td>0.007234</td>\n",
       "      <td>0.010941</td>\n",
       "      <td>0.009939</td>\n",
       "      <td>0.004107</td>\n",
       "      <td>0.005779</td>\n",
       "      <td>0.012274</td>\n",
       "      <td>0.008122</td>\n",
       "      <td>0.003345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.216816</td>\n",
       "      <td>0.221816</td>\n",
       "      <td>0.246783</td>\n",
       "      <td>0.14046</td>\n",
       "      <td>0.235809</td>\n",
       "      <td>0.163086</td>\n",
       "      <td>0.156781</td>\n",
       "      <td>0.060239</td>\n",
       "      <td>0.112462</td>\n",
       "      <td>0.092746</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004954</td>\n",
       "      <td>0.004906</td>\n",
       "      <td>0.007242</td>\n",
       "      <td>0.010978</td>\n",
       "      <td>0.0099</td>\n",
       "      <td>0.004077</td>\n",
       "      <td>0.005749</td>\n",
       "      <td>0.012259</td>\n",
       "      <td>0.008118</td>\n",
       "      <td>0.003335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.219775</td>\n",
       "      <td>0.23027</td>\n",
       "      <td>0.245784</td>\n",
       "      <td>0.127237</td>\n",
       "      <td>0.23554</td>\n",
       "      <td>0.157704</td>\n",
       "      <td>0.158863</td>\n",
       "      <td>0.061349</td>\n",
       "      <td>0.104922</td>\n",
       "      <td>0.090188</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004555</td>\n",
       "      <td>0.005253</td>\n",
       "      <td>0.006774</td>\n",
       "      <td>0.011002</td>\n",
       "      <td>0.009526</td>\n",
       "      <td>0.004282</td>\n",
       "      <td>0.005897</td>\n",
       "      <td>0.011843</td>\n",
       "      <td>0.008147</td>\n",
       "      <td>0.003183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.187624</td>\n",
       "      <td>0.207497</td>\n",
       "      <td>0.2296</td>\n",
       "      <td>0.156831</td>\n",
       "      <td>0.237644</td>\n",
       "      <td>0.158047</td>\n",
       "      <td>0.144264</td>\n",
       "      <td>0.072448</td>\n",
       "      <td>0.124693</td>\n",
       "      <td>0.102878</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005611</td>\n",
       "      <td>0.004742</td>\n",
       "      <td>0.007781</td>\n",
       "      <td>0.011479</td>\n",
       "      <td>0.010574</td>\n",
       "      <td>0.004627</td>\n",
       "      <td>0.005291</td>\n",
       "      <td>0.012359</td>\n",
       "      <td>0.008732</td>\n",
       "      <td>0.004028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.220744</td>\n",
       "      <td>0.230636</td>\n",
       "      <td>0.247647</td>\n",
       "      <td>0.130081</td>\n",
       "      <td>0.236299</td>\n",
       "      <td>0.159477</td>\n",
       "      <td>0.160199</td>\n",
       "      <td>0.060732</td>\n",
       "      <td>0.106523</td>\n",
       "      <td>0.091333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004666</td>\n",
       "      <td>0.005188</td>\n",
       "      <td>0.006886</td>\n",
       "      <td>0.011023</td>\n",
       "      <td>0.009622</td>\n",
       "      <td>0.004199</td>\n",
       "      <td>0.00589</td>\n",
       "      <td>0.011966</td>\n",
       "      <td>0.008181</td>\n",
       "      <td>0.003203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.178998</td>\n",
       "      <td>0.22384</td>\n",
       "      <td>0.226364</td>\n",
       "      <td>0.156991</td>\n",
       "      <td>0.242024</td>\n",
       "      <td>0.157247</td>\n",
       "      <td>0.144798</td>\n",
       "      <td>0.072809</td>\n",
       "      <td>0.125865</td>\n",
       "      <td>0.103305</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005624</td>\n",
       "      <td>0.004856</td>\n",
       "      <td>0.007797</td>\n",
       "      <td>0.011442</td>\n",
       "      <td>0.010568</td>\n",
       "      <td>0.004628</td>\n",
       "      <td>0.005237</td>\n",
       "      <td>0.012326</td>\n",
       "      <td>0.00872</td>\n",
       "      <td>0.004023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2133</td>\n",
       "      <td>0.210749</td>\n",
       "      <td>0.235939</td>\n",
       "      <td>0.144334</td>\n",
       "      <td>0.232312</td>\n",
       "      <td>0.158469</td>\n",
       "      <td>0.151123</td>\n",
       "      <td>0.066397</td>\n",
       "      <td>0.116601</td>\n",
       "      <td>0.096062</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005173</td>\n",
       "      <td>0.004785</td>\n",
       "      <td>0.007331</td>\n",
       "      <td>0.0111</td>\n",
       "      <td>0.010238</td>\n",
       "      <td>0.00439</td>\n",
       "      <td>0.005497</td>\n",
       "      <td>0.012148</td>\n",
       "      <td>0.008332</td>\n",
       "      <td>0.003743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.218168</td>\n",
       "      <td>0.2215</td>\n",
       "      <td>0.246512</td>\n",
       "      <td>0.140721</td>\n",
       "      <td>0.233292</td>\n",
       "      <td>0.163435</td>\n",
       "      <td>0.15673</td>\n",
       "      <td>0.060557</td>\n",
       "      <td>0.111724</td>\n",
       "      <td>0.091997</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004968</td>\n",
       "      <td>0.004907</td>\n",
       "      <td>0.007266</td>\n",
       "      <td>0.010933</td>\n",
       "      <td>0.009858</td>\n",
       "      <td>0.004074</td>\n",
       "      <td>0.00576</td>\n",
       "      <td>0.012259</td>\n",
       "      <td>0.008133</td>\n",
       "      <td>0.003356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.209414</td>\n",
       "      <td>0.207386</td>\n",
       "      <td>0.229831</td>\n",
       "      <td>0.140925</td>\n",
       "      <td>0.233911</td>\n",
       "      <td>0.153187</td>\n",
       "      <td>0.148025</td>\n",
       "      <td>0.070336</td>\n",
       "      <td>0.116016</td>\n",
       "      <td>0.09636</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005017</td>\n",
       "      <td>0.004982</td>\n",
       "      <td>0.007089</td>\n",
       "      <td>0.011165</td>\n",
       "      <td>0.010255</td>\n",
       "      <td>0.004703</td>\n",
       "      <td>0.005604</td>\n",
       "      <td>0.011893</td>\n",
       "      <td>0.008451</td>\n",
       "      <td>0.003884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.212888</td>\n",
       "      <td>0.210792</td>\n",
       "      <td>0.236016</td>\n",
       "      <td>0.144534</td>\n",
       "      <td>0.232489</td>\n",
       "      <td>0.159318</td>\n",
       "      <td>0.150828</td>\n",
       "      <td>0.067133</td>\n",
       "      <td>0.11694</td>\n",
       "      <td>0.09644</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005183</td>\n",
       "      <td>0.004762</td>\n",
       "      <td>0.00733</td>\n",
       "      <td>0.01106</td>\n",
       "      <td>0.010236</td>\n",
       "      <td>0.004405</td>\n",
       "      <td>0.005574</td>\n",
       "      <td>0.012167</td>\n",
       "      <td>0.008345</td>\n",
       "      <td>0.003773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.185033</td>\n",
       "      <td>0.209188</td>\n",
       "      <td>0.232176</td>\n",
       "      <td>0.156852</td>\n",
       "      <td>0.238739</td>\n",
       "      <td>0.158782</td>\n",
       "      <td>0.146274</td>\n",
       "      <td>0.072382</td>\n",
       "      <td>0.12492</td>\n",
       "      <td>0.103255</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005611</td>\n",
       "      <td>0.004768</td>\n",
       "      <td>0.007783</td>\n",
       "      <td>0.011479</td>\n",
       "      <td>0.01056</td>\n",
       "      <td>0.004636</td>\n",
       "      <td>0.005422</td>\n",
       "      <td>0.012377</td>\n",
       "      <td>0.008744</td>\n",
       "      <td>0.004034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.216608</td>\n",
       "      <td>0.219952</td>\n",
       "      <td>0.245795</td>\n",
       "      <td>0.140527</td>\n",
       "      <td>0.231957</td>\n",
       "      <td>0.16259</td>\n",
       "      <td>0.155918</td>\n",
       "      <td>0.060067</td>\n",
       "      <td>0.111345</td>\n",
       "      <td>0.091564</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004938</td>\n",
       "      <td>0.004842</td>\n",
       "      <td>0.007238</td>\n",
       "      <td>0.010884</td>\n",
       "      <td>0.009764</td>\n",
       "      <td>0.004035</td>\n",
       "      <td>0.005701</td>\n",
       "      <td>0.012162</td>\n",
       "      <td>0.008095</td>\n",
       "      <td>0.003321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.22007</td>\n",
       "      <td>0.228184</td>\n",
       "      <td>0.246076</td>\n",
       "      <td>0.129575</td>\n",
       "      <td>0.233766</td>\n",
       "      <td>0.158093</td>\n",
       "      <td>0.159195</td>\n",
       "      <td>0.060615</td>\n",
       "      <td>0.106012</td>\n",
       "      <td>0.090819</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004629</td>\n",
       "      <td>0.005129</td>\n",
       "      <td>0.006858</td>\n",
       "      <td>0.010968</td>\n",
       "      <td>0.009537</td>\n",
       "      <td>0.004181</td>\n",
       "      <td>0.005835</td>\n",
       "      <td>0.011882</td>\n",
       "      <td>0.008142</td>\n",
       "      <td>0.003202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.216328</td>\n",
       "      <td>0.222588</td>\n",
       "      <td>0.246662</td>\n",
       "      <td>0.140056</td>\n",
       "      <td>0.235548</td>\n",
       "      <td>0.163251</td>\n",
       "      <td>0.156797</td>\n",
       "      <td>0.06047</td>\n",
       "      <td>0.112109</td>\n",
       "      <td>0.092845</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004948</td>\n",
       "      <td>0.004938</td>\n",
       "      <td>0.007226</td>\n",
       "      <td>0.010963</td>\n",
       "      <td>0.009901</td>\n",
       "      <td>0.004103</td>\n",
       "      <td>0.005776</td>\n",
       "      <td>0.012275</td>\n",
       "      <td>0.00813</td>\n",
       "      <td>0.003333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51 rows × 600 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        MBP      GFAP       MT3      NRGN       CLU     PTGDS       FTL  \\\n",
       "0  0.215962  0.221578  0.246075   0.13982  0.235637  0.163181  0.156388   \n",
       "0  0.221621  0.230604  0.248126   0.13064  0.235455  0.159403  0.160334   \n",
       "0  0.218238  0.222344  0.246689  0.140295  0.233608  0.163468  0.156773   \n",
       "0  0.189445  0.208594   0.22955  0.155812  0.237425  0.158335  0.145403   \n",
       "0  0.217178  0.221919  0.246266  0.140143  0.234728  0.163801   0.15657   \n",
       "0  0.218565  0.222034  0.246812  0.140923   0.23407  0.163739  0.157119   \n",
       "0  0.216958  0.222568   0.24695  0.140584  0.236033  0.163519  0.156932   \n",
       "0  0.213821  0.211425  0.238745  0.146705  0.234646  0.159277  0.152392   \n",
       "0   0.18616  0.207896  0.230321  0.157334  0.238795  0.159067   0.14454   \n",
       "0  0.217619  0.223081  0.247043   0.14055  0.235746  0.163619    0.1568   \n",
       "0  0.217004  0.224145  0.243915  0.134906  0.234317  0.161318  0.154979   \n",
       "0  0.212212  0.208201  0.236558  0.147034  0.233769  0.158871  0.151534   \n",
       "0  0.186316  0.207945  0.230499  0.157621  0.238985  0.159405  0.144455   \n",
       "0  0.185475  0.208583  0.232269   0.15722  0.238632  0.159465  0.145259   \n",
       "0  0.217011  0.222662  0.246914  0.139946  0.234904  0.163797  0.156816   \n",
       "0  0.217718  0.222919  0.247101  0.140358  0.235108  0.163522  0.157093   \n",
       "0  0.175585  0.206208  0.224314  0.154597  0.239964  0.152937  0.143101   \n",
       "0  0.217602  0.221761  0.246306  0.139853   0.23441  0.163708  0.156507   \n",
       "0  0.216709  0.221875  0.246619  0.140227  0.234581  0.163465  0.156519   \n",
       "0  0.220416  0.229572  0.246966  0.129964  0.235547  0.158967  0.159766   \n",
       "0  0.187308  0.208056  0.229855  0.156334  0.238105  0.157781  0.145339   \n",
       "0  0.218006  0.221368  0.246003  0.140753  0.233117  0.163269  0.156667   \n",
       "0   0.21747  0.222622  0.247031  0.140342  0.235051  0.163601  0.157074   \n",
       "0  0.218414  0.222164  0.246992  0.140515   0.23476  0.163813  0.157031   \n",
       "0  0.218624  0.222714   0.24733     0.141  0.235121  0.164123  0.157138   \n",
       "0  0.191404  0.207009  0.230608  0.156687  0.236977  0.158064  0.147038   \n",
       "0  0.218553  0.223069  0.248091  0.140983  0.235624  0.164665  0.157587   \n",
       "0  0.176662   0.20898  0.224341  0.155148  0.241427  0.151939  0.143133   \n",
       "0  0.217397  0.222344  0.246385  0.140256   0.23439    0.1638  0.156715   \n",
       "0  0.217425  0.221991  0.246316  0.140556  0.235053   0.16296  0.156689   \n",
       "0  0.184646  0.208264  0.230932  0.156379  0.238795  0.158747  0.145681   \n",
       "0  0.218143  0.221959  0.246876  0.140444  0.234075  0.163704  0.156746   \n",
       "0  0.217511  0.223377  0.246721  0.139682  0.235083   0.16356  0.157278   \n",
       "0  0.217397  0.221411  0.246461   0.14062  0.233459  0.163029  0.156369   \n",
       "0  0.216363  0.221941   0.24662  0.139872  0.235789  0.163075  0.156567   \n",
       "0  0.217391  0.222114  0.246239  0.140195  0.233962  0.163045  0.156546   \n",
       "0  0.215493     0.227  0.235861  0.141906  0.235974  0.157988  0.153508   \n",
       "0  0.217102  0.222135  0.245988  0.139989  0.235293  0.163433  0.156346   \n",
       "0  0.216816  0.221816  0.246783   0.14046  0.235809  0.163086  0.156781   \n",
       "0  0.219775   0.23027  0.245784  0.127237   0.23554  0.157704  0.158863   \n",
       "0  0.187624  0.207497    0.2296  0.156831  0.237644  0.158047  0.144264   \n",
       "0  0.220744  0.230636  0.247647  0.130081  0.236299  0.159477  0.160199   \n",
       "0  0.178998   0.22384  0.226364  0.156991  0.242024  0.157247  0.144798   \n",
       "0    0.2133  0.210749  0.235939  0.144334  0.232312  0.158469  0.151123   \n",
       "0  0.218168    0.2215  0.246512  0.140721  0.233292  0.163435   0.15673   \n",
       "0  0.209414  0.207386  0.229831  0.140925  0.233911  0.153187  0.148025   \n",
       "0  0.212888  0.210792  0.236016  0.144534  0.232489  0.159318  0.150828   \n",
       "0  0.185033  0.209188  0.232176  0.156852  0.238739  0.158782  0.146274   \n",
       "0  0.216608  0.219952  0.245795  0.140527  0.231957   0.16259  0.155918   \n",
       "0   0.22007  0.228184  0.246076  0.129575  0.233766  0.158093  0.159195   \n",
       "0  0.216328  0.222588  0.246662  0.140056  0.235548  0.163251  0.156797   \n",
       "\n",
       "     SNAP25     ALDOA    TUBA1B  ...     KCNJ4      CNN3    MRPL55     PSMC5  \\\n",
       "0  0.060474   0.11207  0.092219  ...  0.004927  0.004929  0.007212  0.010926   \n",
       "0  0.060821  0.106623  0.091247  ...  0.004687  0.005183  0.006918  0.011028   \n",
       "0  0.060363  0.112151  0.091829  ...   0.00494  0.004875  0.007271  0.010946   \n",
       "0  0.072136  0.124424   0.10266  ...  0.005577  0.004755  0.007735  0.011442   \n",
       "0  0.060388  0.111889  0.092137  ...  0.004945  0.004918   0.00723  0.010943   \n",
       "0  0.060779  0.111923  0.092322  ...  0.004975  0.004939  0.007273  0.010953   \n",
       "0  0.060683  0.112281  0.092772  ...  0.004976  0.004949  0.007241   0.01096   \n",
       "0  0.066765  0.116888  0.097319  ...   0.00519  0.004779  0.007333  0.011101   \n",
       "0  0.072538  0.125258  0.103259  ...  0.005615   0.00475  0.007791  0.011468   \n",
       "0  0.060671  0.112275  0.092694  ...  0.004966  0.004943  0.007247  0.010958   \n",
       "0   0.06185  0.109186  0.090607  ...  0.004767  0.005105  0.007052  0.010986   \n",
       "0  0.067127  0.117201  0.097162  ...  0.005198  0.004764  0.007355  0.011137   \n",
       "0  0.072637  0.125469  0.103257  ...  0.005625  0.004754  0.007807  0.011478   \n",
       "0  0.072411  0.125046   0.10317  ...  0.005617  0.004763  0.007797  0.011493   \n",
       "0  0.060162  0.112011  0.091605  ...  0.004939  0.004905  0.007253  0.010945   \n",
       "0  0.060702  0.112094  0.092685  ...  0.004945  0.004951  0.007254  0.010941   \n",
       "0  0.078414  0.125411  0.107003  ...  0.005631  0.004869   0.00768  0.011765   \n",
       "0  0.060259  0.112045  0.091654  ...  0.004927  0.004876  0.007239  0.010931   \n",
       "0   0.06015   0.11177  0.092206  ...  0.004941  0.004924  0.007234  0.010921   \n",
       "0   0.06063  0.106425  0.091032  ...  0.004654  0.005162  0.006872  0.010999   \n",
       "0   0.07234  0.124763  0.102994  ...  0.005611  0.004738  0.007759  0.011456   \n",
       "0  0.060886  0.112327  0.092278  ...  0.004976  0.004906  0.007274  0.010943   \n",
       "0  0.060084  0.111522  0.092419  ...  0.004944   0.00495  0.007241  0.010939   \n",
       "0   0.06035  0.111656  0.092123  ...  0.004967  0.004945  0.007249  0.010934   \n",
       "0  0.060598  0.111796  0.092101  ...  0.004972  0.004955  0.007258  0.010965   \n",
       "0  0.072446  0.124659   0.10305  ...  0.005604  0.004719  0.007776  0.011477   \n",
       "0  0.060493  0.112127  0.092484  ...  0.004966  0.004944  0.007262  0.010973   \n",
       "0  0.078819  0.126118  0.107406  ...  0.005672  0.004914  0.007713  0.011849   \n",
       "0  0.060291  0.111957  0.091619  ...  0.004939  0.004891   0.00725  0.010926   \n",
       "0  0.060639  0.111964  0.092781  ...  0.004943  0.004944  0.007239  0.010961   \n",
       "0  0.072181  0.124539  0.102942  ...  0.005599  0.004755  0.007763  0.011443   \n",
       "0  0.060027  0.111635  0.091773  ...  0.004945  0.004913  0.007243  0.010921   \n",
       "0  0.060025  0.111726  0.091692  ...  0.004932  0.004937  0.007232  0.010937   \n",
       "0    0.0604  0.111901  0.092284  ...  0.004954  0.004892  0.007267  0.010929   \n",
       "0  0.059977  0.111902  0.092144  ...  0.004925  0.004911  0.007211  0.010936   \n",
       "0  0.060506  0.111791  0.092229  ...  0.004944   0.00492  0.007248  0.010913   \n",
       "0  0.065001  0.114768  0.094234  ...  0.005023  0.004891  0.007183  0.010948   \n",
       "0  0.060664     0.112  0.092401  ...  0.004948  0.004933  0.007234  0.010941   \n",
       "0  0.060239  0.112462  0.092746  ...  0.004954  0.004906  0.007242  0.010978   \n",
       "0  0.061349  0.104922  0.090188  ...  0.004555  0.005253  0.006774  0.011002   \n",
       "0  0.072448  0.124693  0.102878  ...  0.005611  0.004742  0.007781  0.011479   \n",
       "0  0.060732  0.106523  0.091333  ...  0.004666  0.005188  0.006886  0.011023   \n",
       "0  0.072809  0.125865  0.103305  ...  0.005624  0.004856  0.007797  0.011442   \n",
       "0  0.066397  0.116601  0.096062  ...  0.005173  0.004785  0.007331    0.0111   \n",
       "0  0.060557  0.111724  0.091997  ...  0.004968  0.004907  0.007266  0.010933   \n",
       "0  0.070336  0.116016   0.09636  ...  0.005017  0.004982  0.007089  0.011165   \n",
       "0  0.067133   0.11694   0.09644  ...  0.005183  0.004762   0.00733   0.01106   \n",
       "0  0.072382   0.12492  0.103255  ...  0.005611  0.004768  0.007783  0.011479   \n",
       "0  0.060067  0.111345  0.091564  ...  0.004938  0.004842  0.007238  0.010884   \n",
       "0  0.060615  0.106012  0.090819  ...  0.004629  0.005129  0.006858  0.010968   \n",
       "0   0.06047  0.112109  0.092845  ...  0.004948  0.004938  0.007226  0.010963   \n",
       "\n",
       "      GNAO1    PRKACB      RGCC      BIN1    NDUFA8     NCALD  \n",
       "0   0.00991  0.004103  0.005752  0.012232  0.008097  0.003337  \n",
       "0  0.009602  0.004183  0.005903  0.011984  0.008185  0.003196  \n",
       "0  0.009829  0.004056  0.005731   0.01227  0.008109  0.003324  \n",
       "0  0.010549  0.004613  0.005309  0.012325  0.008715  0.004008  \n",
       "0   0.00989  0.004079  0.005749  0.012255  0.008111  0.003329  \n",
       "0  0.009886  0.004088  0.005762   0.01228  0.008149  0.003367  \n",
       "0  0.009974  0.004117  0.005786  0.012298  0.008145  0.003359  \n",
       "0  0.010275  0.004413  0.005535  0.012199  0.008355  0.003788  \n",
       "0  0.010606  0.004625  0.005313  0.012352  0.008739  0.004031  \n",
       "0  0.009952  0.004116  0.005803  0.012311  0.008143  0.003346  \n",
       "0  0.009766  0.004259  0.005817  0.012103  0.008129  0.003294  \n",
       "0  0.010256  0.004419   0.00552  0.012155  0.008357  0.003799  \n",
       "0  0.010627  0.004628  0.005308  0.012398  0.008751   0.00403  \n",
       "0  0.010584  0.004626   0.00533  0.012367  0.008737  0.004031  \n",
       "0  0.009864  0.004063   0.00574  0.012255  0.008089  0.003288  \n",
       "0  0.009918  0.004113  0.005784  0.012277  0.008122  0.003351  \n",
       "0  0.010626  0.004981   0.00522  0.012096  0.009062  0.004223  \n",
       "0  0.009847  0.004054  0.005747  0.012236  0.008096  0.003309  \n",
       "0  0.009873  0.004074  0.005757   0.01224  0.008115  0.003327  \n",
       "0  0.009598   0.00418  0.005878  0.011942   0.00816  0.003184  \n",
       "0  0.010539  0.004635  0.005392  0.012335  0.008724  0.004035  \n",
       "0  0.009883  0.004094   0.00574  0.012261  0.008131  0.003389  \n",
       "0  0.009896  0.004073  0.005746  0.012274  0.008117  0.003316  \n",
       "0  0.009893  0.004063  0.005782  0.012265  0.008124  0.003322  \n",
       "0  0.009913  0.004071  0.005815  0.012279  0.008139  0.003327  \n",
       "0  0.010545  0.004632   0.00535   0.01241  0.008724  0.004032  \n",
       "0  0.009912  0.004093  0.005773   0.01229  0.008159  0.003352  \n",
       "0  0.010634  0.005018  0.005274  0.012169  0.009101  0.004253  \n",
       "0  0.009845  0.004065  0.005723  0.012249  0.008093  0.003324  \n",
       "0   0.00994  0.004111  0.005759  0.012269  0.008138  0.003364  \n",
       "0  0.010544  0.004628  0.005421  0.012336   0.00872  0.004032  \n",
       "0  0.009842  0.004044  0.005767  0.012265   0.00811  0.003293  \n",
       "0  0.009866  0.004061  0.005745  0.012248  0.008093  0.003298  \n",
       "0  0.009869  0.004077  0.005755  0.012259  0.008135  0.003342  \n",
       "0  0.009879  0.004067  0.005755  0.012232  0.008086  0.003307  \n",
       "0  0.009868  0.004091  0.005753   0.01224  0.008111  0.003336  \n",
       "0  0.010106  0.004324  0.005536  0.012043  0.008191  0.003684  \n",
       "0  0.009939  0.004107  0.005779  0.012274  0.008122  0.003345  \n",
       "0    0.0099  0.004077  0.005749  0.012259  0.008118  0.003335  \n",
       "0  0.009526  0.004282  0.005897  0.011843  0.008147  0.003183  \n",
       "0  0.010574  0.004627  0.005291  0.012359  0.008732  0.004028  \n",
       "0  0.009622  0.004199   0.00589  0.011966  0.008181  0.003203  \n",
       "0  0.010568  0.004628  0.005237  0.012326   0.00872  0.004023  \n",
       "0  0.010238   0.00439  0.005497  0.012148  0.008332  0.003743  \n",
       "0  0.009858  0.004074   0.00576  0.012259  0.008133  0.003356  \n",
       "0  0.010255  0.004703  0.005604  0.011893  0.008451  0.003884  \n",
       "0  0.010236  0.004405  0.005574  0.012167  0.008345  0.003773  \n",
       "0   0.01056  0.004636  0.005422  0.012377  0.008744  0.004034  \n",
       "0  0.009764  0.004035  0.005701  0.012162  0.008095  0.003321  \n",
       "0  0.009537  0.004181  0.005835  0.011882  0.008142  0.003202  \n",
       "0  0.009901  0.004103  0.005776  0.012275   0.00813  0.003333  \n",
       "\n",
       "[51 rows x 600 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_hat_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a65dc033",
   "metadata": {},
   "outputs": [],
   "source": [
    "MOFApred = pd.read_csv(\"./MOFA_imputed_ROSMAP_GE.csv\")\n",
    "# MOFApred.index = MOFApred[\"Unnamed: 0\"]\n",
    "# MOFApred = MOFApred.drop([\"Unnamed: 0\"], axis=1)\n",
    "# MOFApred = MOFApred.T\n",
    "# MOFApred = MOFApred.reset_index(drop=True)\n",
    "# MOFApred\n",
    "\n",
    "# MOFApred = MOFApred[-51:]\n",
    "\n",
    "predCorrMOFA = []\n",
    "for i in range(len(MOFApred)):\n",
    "    a = MOFApred.iloc[i][:]\n",
    "    b = X_hat.iloc[i][:]\n",
    "    corr = stats.pearsonr(a,b)\n",
    "    predCorrMOFA.append(corr[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6e33bf50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8819680497724112,\n",
       " 0.9721258012507401,\n",
       " 0.9805685567047402,\n",
       " 0.9824845225027259,\n",
       " 0.8612732103206302,\n",
       " 0.9353006609891139,\n",
       " 0.8872815902733876,\n",
       " 0.856088917294918,\n",
       " 0.8542736129748746,\n",
       " 0.9127096875941785,\n",
       " 0.916649371402424,\n",
       " 0.9590045412253948,\n",
       " 0.9383509322522914,\n",
       " 0.8947989452454592,\n",
       " 0.8779528495418679,\n",
       " 0.8893551302195528,\n",
       " 0.8762583053919518,\n",
       " 0.9143195563366503,\n",
       " 0.9516954265606536,\n",
       " 0.9351700799556654,\n",
       " 0.7321411545147138,\n",
       " 0.9347716081556058,\n",
       " 0.9405309195903515,\n",
       " 0.8800587878216292,\n",
       " 0.9795025773476356,\n",
       " 0.924420134221009,\n",
       " 0.9719079780752157,\n",
       " 0.9506490631740797,\n",
       " 0.9321446847781747,\n",
       " 0.9770551974435855,\n",
       " 0.913721701481642,\n",
       " 0.9430805940106409,\n",
       " 0.9892470773341021,\n",
       " 0.9713646594570511,\n",
       " 0.9579675419299151,\n",
       " 0.9855548248826698,\n",
       " 0.977185394822554,\n",
       " 0.9563456121898929,\n",
       " 0.9182345125609772,\n",
       " 0.6804446638753017,\n",
       " 0.771775962392899,\n",
       " 0.9612726479768581,\n",
       " 0.8785047691504733,\n",
       " 0.8783809811986881,\n",
       " 0.9603260262752111,\n",
       " 0.8975109863249939,\n",
       " 0.9574193375483876,\n",
       " 0.8870909626208203,\n",
       " 0.9593033518369881,\n",
       " 0.8810242596039602,\n",
       " 0.9709142134246929]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predtion_Corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "12ec5d36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predCorrdf = pd.DataFrame(predtion_Corr,columns=['CMOT_clustering'])\n",
    "predCorrdf[\"MOFA+\"] = predCorrMOFA\n",
    "\n",
    "df = pd.DataFrame(columns=[\"CMOT\",\"MOFA+\"])\n",
    "df.loc[\"Mean \\ncorrelation\"] = predCorrdf.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b4cf763f",
   "metadata": {},
   "outputs": [],
   "source": [
    "seuratCorr = [0.9277504124543483,\n",
    " 0.9810311341435238,\n",
    " 0.9718438234498497,\n",
    " 0.9871670666894896,\n",
    " 0.9015693622315528,\n",
    " 0.9344781973909385,\n",
    " 0.9272883436821672,\n",
    " 0.9173956277918374,\n",
    " 0.864892266292827,\n",
    " 0.9395216542783325,\n",
    " 0.9414501870963133,\n",
    " 0.9669586700238845,\n",
    " 0.9259233949409168,\n",
    " 0.9553211627557432,\n",
    " 0.9168011492113513,\n",
    " 0.9149729939253788,\n",
    " 0.9365844613196062,\n",
    " 0.9467400377815167,\n",
    " 0.947583941646314,\n",
    " 0.942365844144423,\n",
    " 0.7443527547864296,\n",
    " 0.9557969656352285,\n",
    " 0.9522651833577265,\n",
    " 0.9064044910063547,\n",
    " 0.9772066820515395,\n",
    " 0.8735812489580761,\n",
    " 0.9786938059927054,\n",
    " 0.9557307275728614,\n",
    " 0.9221623708027873,\n",
    " 0.9843218314605442,\n",
    " 0.936353649784899,\n",
    " 0.9491802717935207,\n",
    " 0.9825519732235904,\n",
    " 0.9791993937540917,\n",
    " 0.9520854196637722,\n",
    " 0.9767394146928516,\n",
    " 0.9772898843582494,\n",
    " 0.9787674081996964,\n",
    " 0.9319352010098463,\n",
    " 0.7055301945894832,\n",
    " 0.8317328219255395,\n",
    " 0.9627877439134784,\n",
    " 0.9445138754167258,\n",
    " 0.896179357612554,\n",
    " 0.9665412891594236,\n",
    " 0.911384886263447,\n",
    " 0.9716040216516999,\n",
    " 0.9043507404793713,\n",
    " 0.971221355182617,\n",
    " 0.8573201581464882,\n",
    " 0.9766096308411782]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "06c66014",
   "metadata": {},
   "outputs": [],
   "source": [
    "predCorrdf[\"Seurat\"] = seuratCorr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e4002099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predCorrdf.boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2346021",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de8fb2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492567e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
